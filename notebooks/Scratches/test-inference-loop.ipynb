{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# Always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from src.models import predict_model, seq2seq\n",
    "import socialml\n",
    "import src.data.msg_pipeline as mp\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "import numpy as np\n",
    "from src.data.word_utils import Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "experiment = 'exp02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join('../models/checkpoints', experiment)\n",
    "vocab_filepath = os.path.join(checkpoint_dir, 'vocab.json')\n",
    "data_spec_filepath = os.path.join('../specs', 'data_specs.yaml')\n",
    "model_spec_filepath = os.path.join('../specs', experiment+'.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "specs = predict_model.load_yaml(model_spec_filepath)\n",
    "vocab = Vocab(vocab_filepath)\n",
    "\n",
    "model, encoder_model, decoder_model = seq2seq.build_model(**specs['model_params'], vocab_size=len(vocab))\n",
    "original_weights = decoder_model.layers[4].get_weights()\n",
    "model.load_weights(predict_model.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Predicting single response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "seq_inf = predict_model.SeqInference(vocab_filepath,\n",
    "                                     encoder_model,\n",
    "                                     decoder_model,\n",
    "                                     data_spec_filepath,\n",
    "                                     verbose=1,\n",
    "                                     method='beam_search',\n",
    "                                     max_decoder_seq_length=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_inf.tokenizer.inverse_transform(4194)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type a message hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sent message: \n",
      " hello \n",
      "\n",
      "Tokenizing mesage: hello\n",
      "Sending context: [   2 4194    1] to encoder\n",
      "Current beam sequence \n",
      " [[    1     2]\n",
      " [    1 18624]\n",
      " [    1    17]]\n",
      "Appending [1 2] to final tokens\n",
      "Current beam sequence \n",
      " [[    1 18624  4767]\n",
      " [    1 18624    39]\n",
      " [    1 18624     2]]\n",
      "Appending [    1 18624     2] to final tokens\n",
      "Current beam sequence \n",
      " [[    1 18624    39     2]\n",
      " [    1 18624    39    88]\n",
      " [    1 18624    39     7]]\n",
      "Appending [    1 18624    39     2] to final tokens\n",
      "Current beam sequence \n",
      " [[    1 18624    39    88     2]\n",
      " [    1 18624    39    88    37]\n",
      " [    1 18624    39    88   280]]\n",
      "Appending [    1 18624    39    88     2] to final tokens\n",
      "Current beam sequence \n",
      " [[    1 18624    39    88    37   280]\n",
      " [    1 18624    39    88    37    31]\n",
      " [    1 18624    39    88    37     2]]\n",
      "Appending [    1 18624    39    88    37     2] to final tokens\n",
      "\n",
      " Returned message: \n",
      " noooooooo is\n"
     ]
    }
   ],
   "source": [
    "msg_ = input('Type a message');\n",
    "print('\\n', 'Sent message: \\n', msg_, '\\n')\n",
    "out = seq_inf.predict_response_from_text(msg_)\n",
    "print('\\n', 'Returned message: \\n',out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Multiple Resposne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "chat = predict_model.Chat(vocab_filepath,\n",
    "                                     encoder_model,\n",
    "                                     decoder_model,\n",
    "                                     data_spec_filepath,\n",
    "                                     verbose=1,\n",
    "                                     method='beam_search',\n",
    "                                     max_decoder_seq_length=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reverse_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "chat.add_tokens_to_context([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "a = np.asarray([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "a = a[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 2, 1])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([    2,    39, 18624,     1]), array([   2, 4194,    1])]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending context: [   2   16 4194    1] to encoder\n",
      "Current beam sequence \n",
      " [[ 1  2]\n",
      " [ 1 17]\n",
      " [ 1  6]]\n",
      "Appending [1 2] to final tokens\n",
      "Current beam sequence \n",
      " [[  1   6 174]\n",
      " [  1  17 174]\n",
      " [  1  17 307]]\n",
      "Current beam sequence \n",
      " [[  1  17 174 419]\n",
      " [  1  17 307   7]\n",
      " [  1  17 307  17]]\n",
      "Current beam sequence \n",
      " [[  1  17 307   7   8]\n",
      " [  1  17 307  17   2]\n",
      " [  1  17 307  17 419]]\n",
      "Appending [  1  17 307  17   2] to final tokens\n",
      "Current beam sequence \n",
      " [[  1  17 307  17 419   8]\n",
      " [  1  17 307  17 419 485]\n",
      " [  1  17 307  17 419  44]]\n",
      "Current beam sequence \n",
      " [[  1  17 307  17 419  44  53]\n",
      " [  1  17 307  17 419  44  37]\n",
      " [  1  17 307  17 419  44 914]]\n",
      "Current beam sequence \n",
      " [[  1  17 307  17 419  44 914   2]\n",
      " [  1  17 307  17 419  44 914 123]\n",
      " [  1  17 307  17 419  44 914 229]]\n",
      "Appending [  1  17 307  17 419  44 914   2] to final tokens\n",
      "Current beam sequence \n",
      " [[  1  17 307  17 419  44 914 229   2]\n",
      " [  1  17 307  17 419  44 914 229  71]\n",
      " [  1  17 307  17 419  44 914 229  14]]\n",
      "Appending [  1  17 307  17 419  44 914 229   2] to final tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i was i'"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.send('hello mate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
